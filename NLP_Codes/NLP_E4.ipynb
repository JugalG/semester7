{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "787ff5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import RegexpParser\n",
    "# from nltk.parse.stanford import StanfordParser\n",
    "# import stanfordnlp\n",
    "# import spacy\n",
    "from spacy_download import load_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f54602d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\jugal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\jugal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jugal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\jugal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\jugal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jugal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('treebank')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "191bef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_reviewss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30cb29d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Overall_Rating</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rate for two</th>\n",
       "      <th>City</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oliver Brown</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Cafe, Coffee, Shake, Juices, Beverages, Waffle...</td>\n",
       "      <td>500</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>Been to this place times Prakash is always ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oliver Brown</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Cafe, Coffee, Shake, Juices, Beverages, Waffle...</td>\n",
       "      <td>500</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>I recently visited Oliver Brown on a weekend f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Crush Coffee</td>\n",
       "      <td>3</td>\n",
       "      <td>Cafe, Shake, Beverages, Desserts</td>\n",
       "      <td>600</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>Very watery ans thin shake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Mohalla</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>550</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>it was not cheese burst pizza only cheeze was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Mohalla</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>550</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>Yammitest burger is best I love this BergerAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>The Shaka Cafe</td>\n",
       "      <td>4.3</td>\n",
       "      <td>North Indian, Pizza, Asian, Chinese, Cafe, Des...</td>\n",
       "      <td>1,200</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>food was not spicy which I was told to restora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The Shaka Cafe</td>\n",
       "      <td>4.3</td>\n",
       "      <td>North Indian, Pizza, Asian, Chinese, Cafe, Des...</td>\n",
       "      <td>1,200</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>Punjabi Thali is great The taste was good and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index            Name Overall_Rating  \\\n",
       "0      0    Oliver Brown            3.9   \n",
       "1      1    Oliver Brown            3.9   \n",
       "2      2    Crush Coffee              3   \n",
       "3      3     The Mohalla            3.8   \n",
       "4      4     The Mohalla            3.8   \n",
       "5      5  The Shaka Cafe            4.3   \n",
       "6      6  The Shaka Cafe            4.3   \n",
       "\n",
       "                                             Cuisine Rate for two       City  \\\n",
       "0  Cafe, Coffee, Shake, Juices, Beverages, Waffle...          500  ahmedabad   \n",
       "1  Cafe, Coffee, Shake, Juices, Beverages, Waffle...          500  ahmedabad   \n",
       "2                   Cafe, Shake, Beverages, Desserts          600  ahmedabad   \n",
       "3                                               Cafe          550  ahmedabad   \n",
       "4                                               Cafe          550  ahmedabad   \n",
       "5  North Indian, Pizza, Asian, Chinese, Cafe, Des...        1,200  ahmedabad   \n",
       "6  North Indian, Pizza, Asian, Chinese, Cafe, Des...        1,200  ahmedabad   \n",
       "\n",
       "                                              Review  \n",
       "0  Been to this place times Prakash is always ver...  \n",
       "1  I recently visited Oliver Brown on a weekend f...  \n",
       "2                         Very watery ans thin shake  \n",
       "3  it was not cheese burst pizza only cheeze was ...  \n",
       "4  Yammitest burger is best I love this BergerAnd...  \n",
       "5  food was not spicy which I was told to restora...  \n",
       "6  Punjabi Thali is great The taste was good and ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3fcfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "548d6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['Review'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "477882c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [Been, to, this, place, times, Prakash, is, al...\n",
       "1      [I, recently, visited, Oliver, Brown, on, a, w...\n",
       "2                       [Very, watery, ans, thin, shake]\n",
       "3      [it, was, not, cheese, burst, pizza, only, che...\n",
       "4      [Yammitest, burger, is, best, I, love, this, B...\n",
       "                             ...                        \n",
       "770    [The, taste, is, good, but, the, quantity, is,...\n",
       "771                           [pathetic, food, rejected]\n",
       "772    [thupka, pack, on, cold, drink, packing, taste...\n",
       "773                                 [very, fast, dilver]\n",
       "774    [Tried, their, Hummus, and, Pita, bread, today...\n",
       "Name: tokenized, Length: 775, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c8d1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entities'] = df['tokenized'].apply(nltk.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "170de48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [(Been, NNP), (to, TO), (this, DT), (place, NN...\n",
       "1      [(I, PRP), (recently, RB), (visited, VBD), (Ol...\n",
       "2      [(Very, RB), (watery, JJ), (ans, NNS), (thin, ...\n",
       "3      [(it, PRP), (was, VBD), (not, RB), (cheese, JJ...\n",
       "4      [(Yammitest, JJS), (burger, NN), (is, VBZ), (b...\n",
       "                             ...                        \n",
       "770    [(The, DT), (taste, NN), (is, VBZ), (good, JJ)...\n",
       "771        [(pathetic, JJ), (food, NN), (rejected, VBD)]\n",
       "772    [(thupka, JJ), (pack, NN), (on, IN), (cold, JJ...\n",
       "773               [(very, RB), (fast, RB), (dilver, NN)]\n",
       "774    [(Tried, VBN), (their, PRP$), (Hummus, NNP), (...\n",
       "Name: entities, Length: 775, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19aef5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_pattern = \"\"\"\n",
    "    NP: {<DT>?<JJ>*<NN>}\n",
    "    PP: {<IN><NP>}\n",
    "    VBD: {<VBD>}\n",
    "    IN: {<IN>}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "945edb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = RegexpParser(grammar_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23b6e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "df['chunks'] = df['entities'].apply(chunker.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3228523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [(Been, NNP), (to, TO), [(this, DT), (place, N...\n",
       "1      [(I, PRP), (recently, RB), [(visited, VBD)], (...\n",
       "2      [(Very, RB), (watery, JJ), (ans, NNS), [(thin,...\n",
       "3      [(it, PRP), [(was, VBD)], (not, RB), [(cheese,...\n",
       "4      [(Yammitest, JJS), [(burger, NN)], (is, VBZ), ...\n",
       "                             ...                        \n",
       "770    [[(The, DT), (taste, NN)], (is, VBZ), (good, J...\n",
       "771    [[(pathetic, JJ), (food, NN)], [(rejected, VBD)]]\n",
       "772    [[(thupka, JJ), (pack, NN)], [(on, IN), [('col...\n",
       "773             [(very, RB), (fast, RB), [(dilver, NN)]]\n",
       "774    [(Tried, VBN), (their, PRP$), (Hummus, NNP), (...\n",
       "Name: chunks, Length: 775, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99c3ec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     S                                                                                        \n",
      "   __________________________________________________________________|___________________________________________________________________________________      \n",
      "  |       |      |      |      |         |         |      |          |         |      |       |              NP                  NP               IN     NP   \n",
      "  |       |      |      |      |         |         |      |          |         |      |       |         _____|_____         _____|_______         |      |     \n",
      "is/VBZ good/JJ but/CC is/VBZ low/JJ compared/VBN to/TO would/MD recommend/VB it/PRP to/TO others/NNS The/DT     taste/NN the/DT     quantity/NN as/IN price/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.Tree.fromstring(str(df['chunks'][770])).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90fbae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load_spacy('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68c92314",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_parse_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8fc8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in df['Review']:\n",
    "  doc = nlp(sentence)\n",
    "\n",
    "  dependencies = []\n",
    "  for token in doc:\n",
    "    dependencies.append({\n",
    "        \"word\":token.text,\n",
    "        \"lemma\":token.lemma_,\n",
    "        \"pos\":token.pos_,\n",
    "        \"dep\":token.dep_,\n",
    "        \"head\":token.head.text\n",
    "    })\n",
    "\n",
    "    deep_parse_results.append(dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ff69b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Been', 'lemma': 'be', 'pos': 'AUX', 'dep': 'advcl', 'head': 'is'},\n",
       " {'word': 'to', 'lemma': 'to', 'pos': 'ADP', 'dep': 'prep', 'head': 'Been'},\n",
       " {'word': 'this',\n",
       "  'lemma': 'this',\n",
       "  'pos': 'DET',\n",
       "  'dep': 'det',\n",
       "  'head': 'place'},\n",
       " {'word': 'place',\n",
       "  'lemma': 'place',\n",
       "  'pos': 'NOUN',\n",
       "  'dep': 'pobj',\n",
       "  'head': 'to'},\n",
       " {'word': 'times',\n",
       "  'lemma': 'time',\n",
       "  'pos': 'NOUN',\n",
       "  'dep': 'npadvmod',\n",
       "  'head': 'Been'},\n",
       " {'word': 'Prakash',\n",
       "  'lemma': 'Prakash',\n",
       "  'pos': 'PROPN',\n",
       "  'dep': 'nsubj',\n",
       "  'head': 'is'},\n",
       " {'word': 'is', 'lemma': 'be', 'pos': 'AUX', 'dep': 'ROOT', 'head': 'is'},\n",
       " {'word': 'always',\n",
       "  'lemma': 'always',\n",
       "  'pos': 'ADV',\n",
       "  'dep': 'advmod',\n",
       "  'head': 'is'},\n",
       " {'word': 'very',\n",
       "  'lemma': 'very',\n",
       "  'pos': 'ADV',\n",
       "  'dep': 'advmod',\n",
       "  'head': 'sweet'},\n",
       " {'word': 'sweet',\n",
       "  'lemma': 'sweet',\n",
       "  'pos': 'ADJ',\n",
       "  'dep': 'acomp',\n",
       "  'head': 'is'},\n",
       " {'word': 'and', 'lemma': 'and', 'pos': 'CCONJ', 'dep': 'cc', 'head': 'sweet'},\n",
       " {'word': 'accommodating',\n",
       "  'lemma': 'accommodate',\n",
       "  'pos': 'VERB',\n",
       "  'dep': 'conj',\n",
       "  'head': 'sweet'},\n",
       " {'word': 'Plus', 'lemma': 'plus', 'pos': 'CCONJ', 'dep': 'cc', 'head': 'is'},\n",
       " {'word': 'always',\n",
       "  'lemma': 'always',\n",
       "  'pos': 'ADV',\n",
       "  'dep': 'advmod',\n",
       "  'head': 'ask'},\n",
       " {'word': 'ask', 'lemma': 'ask', 'pos': 'VERB', 'dep': 'conj', 'head': 'is'},\n",
       " {'word': 'Vaibhav',\n",
       "  'lemma': 'Vaibhav',\n",
       "  'pos': 'PROPN',\n",
       "  'dep': 'dobj',\n",
       "  'head': 'ask'},\n",
       " {'word': 'to', 'lemma': 'to', 'pos': 'PART', 'dep': 'aux', 'head': 'make'},\n",
       " {'word': 'make',\n",
       "  'lemma': 'make',\n",
       "  'pos': 'VERB',\n",
       "  'dep': 'xcomp',\n",
       "  'head': 'ask'},\n",
       " {'word': 'your',\n",
       "  'lemma': 'your',\n",
       "  'pos': 'PRON',\n",
       "  'dep': 'poss',\n",
       "  'head': 'shakes'},\n",
       " {'word': 'shakes',\n",
       "  'lemma': 'shake',\n",
       "  'pos': 'NOUN',\n",
       "  'dep': 'dobj',\n",
       "  'head': 'make'},\n",
       " {'word': 'they',\n",
       "  'lemma': 'they',\n",
       "  'pos': 'PRON',\n",
       "  'dep': 'nsubj',\n",
       "  'head': 'are'},\n",
       " {'word': 'are', 'lemma': 'be', 'pos': 'AUX', 'dep': 'ccomp', 'head': 'make'},\n",
       " {'word': 'perfect',\n",
       "  'lemma': 'perfect',\n",
       "  'pos': 'ADJ',\n",
       "  'dep': 'acomp',\n",
       "  'head': 'are'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_parse_results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
