{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5e4899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# import en_core_web_sm\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54a2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621e23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_reviewss.csv')\n",
    "data = data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937bb9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review1:\n",
      "Token: Been, Lemma: be, POS: AUX\n",
      "Token: to, Lemma: to, POS: ADP\n",
      "Token: this, Lemma: this, POS: DET\n",
      "Token: place, Lemma: place, POS: NOUN\n",
      "Token: times, Lemma: time, POS: NOUN\n",
      "\n",
      "\n",
      "Review2:\n",
      "Token: I, Lemma: I, POS: PRON\n",
      "Token: recently, Lemma: recently, POS: ADV\n",
      "Token: visited, Lemma: visit, POS: VERB\n",
      "Token: Oliver, Lemma: Oliver, POS: PROPN\n",
      "Token: Brown, Lemma: Brown, POS: PROPN\n",
      "\n",
      "\n",
      "Review3:\n",
      "Token: Very, Lemma: very, POS: ADV\n",
      "Token: watery, Lemma: watery, POS: ADJ\n",
      "Token: ans, Lemma: ans, POS: PROPN\n",
      "Token: thin, Lemma: thin, POS: ADJ\n",
      "Token: shake, Lemma: shake, POS: NOUN\n",
      "\n",
      "\n",
      "Review4:\n",
      "Token: it, Lemma: it, POS: PRON\n",
      "Token: was, Lemma: be, POS: AUX\n",
      "Token: not, Lemma: not, POS: PART\n",
      "Token: cheese, Lemma: cheese, POS: NOUN\n",
      "Token: burst, Lemma: burst, POS: VERB\n",
      "\n",
      "\n",
      "Review5:\n",
      "Token: Yammitest, Lemma: yammitest, POS: ADJ\n",
      "Token: burger, Lemma: burger, POS: NOUN\n",
      "Token: is, Lemma: be, POS: AUX\n",
      "Token: best, Lemma: good, POS: ADJ\n",
      "Token: I, Lemma: I, POS: PRON\n",
      "\n",
      "\n",
      "Review6:\n",
      "Token: food, Lemma: food, POS: NOUN\n",
      "Token: was, Lemma: be, POS: AUX\n",
      "Token: not, Lemma: not, POS: PART\n",
      "Token: spicy, Lemma: spicy, POS: ADJ\n",
      "Token: which, Lemma: which, POS: PRON\n",
      "\n",
      "\n",
      "Review7:\n",
      "Token: Punjabi, Lemma: Punjabi, POS: PROPN\n",
      "Token: Thali, Lemma: Thali, POS: PROPN\n",
      "Token: is, Lemma: be, POS: AUX\n",
      "Token: great, Lemma: great, POS: ADJ\n",
      "Token: The, Lemma: the, POS: DET\n",
      "\n",
      "\n",
      "Review8:\n",
      "Token: The, Lemma: the, POS: DET\n",
      "Token: owner, Lemma: owner, POS: NOUN\n",
      "Token: did, Lemma: did, POS: AUX\n",
      "Token: nt, Lemma: nt, POS: PART\n",
      "Token: let, Lemma: let, POS: VERB\n",
      "\n",
      "\n",
      "Review9:\n",
      "Token: Both, Lemma: both, POS: DET\n",
      "Token: coffees, Lemma: coffee, POS: NOUN\n",
      "Token: were, Lemma: be, POS: AUX\n",
      "Token: spilled, Lemma: spill, POS: VERB\n",
      "Token: and, Lemma: and, POS: CCONJ\n",
      "\n",
      "\n",
      "Review10:\n",
      "Token: washroom, Lemma: washroom, POS: NOUN\n",
      "Token: was, Lemma: be, POS: AUX\n",
      "Token: not, Lemma: not, POS: PART\n",
      "Token: available, Lemma: available, POS: ADJ\n",
      "Token: had, Lemma: have, POS: VERB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_morphological_analysis(text):\n",
    "    doc = nlp(text)\n",
    "    analyzed_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        analyzed_tokens.append({\n",
    "            'Token': token.text,\n",
    "            'Lemma': token.lemma_,\n",
    "            'POS': token.pos_\n",
    "        })\n",
    "    \n",
    "    return analyzed_tokens\n",
    "\n",
    "# Iterate through the dataset and perform morphological analysis for each synopsis\n",
    "for index, row in data.iterrows():\n",
    "    synopsis = row['Review']\n",
    "    analyzed_tokens = perform_morphological_analysis(synopsis)\n",
    "    \n",
    "    # Print the results for the first few tokens in the synopsis\n",
    "    print(f\"Review{index + 1}:\")\n",
    "    for token_info in analyzed_tokens[:5]:  # Display the first 5 tokens\n",
    "        print(f\"Token: {token_info['Token']}, Lemma: {token_info['Lemma']}, POS: {token_info['POS']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d722ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1bc49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
